{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alarcon7a/gemini_ai_python/blob/main/Gemini_pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Pro (API)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cQh7SPLqjvZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Google Dev https://ai.google.dev/\n",
        "2. Proyecto Gemini : https://deepmind.google/technologies/gemini/\n",
        "3. Gemini - Python: https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b2vuEqHujvZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando algunas librerias"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nGnHnvifjvZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hSwQgQUBjvZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando librerias"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HBayep53jvZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kRXnhAVkjvZL"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asignando el API Key"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "x2fzV6RKjvZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = getpass('Enter the secret value: ')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5kkVBUwjvZN",
        "outputId": "b15acdf6-d07c-40cb-aa56-fd4c9b883196"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nrmFBrc2jvZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos disponibles de Gemini"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G5SwVi-wjvZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "P_Q2ihK0jvZO",
        "outputId": "7b56b5c6-7fcb-4948-e6fb-41e08140ab96"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini pro"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G1SGd2LojvZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuracion del LLM"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Kh5gIJttjvZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    \"temperature\": 0.8,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e6EmFwz8jvZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro',generation_config=generation_config)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6tywqxarjvZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencia sobre el modelo de texto"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dgulvSzZjvZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 71.7 ms, sys: 8.74 ms, total: 80.4 ms\n",
            "Wall time: 5.69 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ```python\n> import pandas as pd\n> \n> # Crear un DataFrame con fechas de datetime64[ns]\n> df = pd.DataFrame({'fecha_inicial': ['2023-01-01', '2023-02-01', '2023-03-01'],\n>                    'fecha_final': ['2023-01-15', '2023-02-15', '2023-03-15']})\n> \n> # Convertir las fechas a objetos datetime\n> df['fecha_inicial'] = pd.to_datetime(df['fecha_inicial'])\n> df['fecha_final'] = pd.to_datetime(df['fecha_final'])\n> \n> # Calcular la diferencia de días entre las fechas\n> df['diferencia_dias'] = (df['fecha_final'] - df['fecha_inicial']).dt.days\n> \n> # Imprimir el DataFrame resultante\n> print(df)\n> \n> # Salida\n> \n>        fecha_inicial fecha_final  diferencia_dias\n> 0 2023-01-01     2023-01-15                14\n> 1 2023-02-01     2023-02-15                14\n> 2 2023-03-01     2023-03-15                14\n> ```"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Dame el codigo de un dataframe de pandas para sacar la diferencia de dias entre  fechas de datetime64[ns]\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "4y3gLoEUjvZh",
        "outputId": "222e96ca-e93c-4d19-ee83-be6bf182b222"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 76.9 ms, sys: 9.76 ms, total: 86.6 ms\n",
            "Wall time: 7.9 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Había una vez en una galaxia muy, muy lejana, un encuentro poco probable entre dos personajes legendarios de universos diferentes. Darth Vader, el Lord Sith más poderoso del Imperio Galáctico, y Goku, el Saiyan más fuerte de Dragon Ball Z, se encontraron en un planeta remoto.\n> \n> Darth Vader, en su búsqueda por conquistar la galaxia, había oído hablar de un guerrero excepcional en un universo paralelo. Decidió viajar a la Tierra para desafiarlo y demostrar su superioridad. Por otro lado, Goku, en su constante esfuerzo por mejorar sus habilidades, estaba emocionado por la oportunidad de luchar contra un oponente digno.\n> \n> Cuando se enfrentaron, el choque de sus poderes fue impresionante. Darth Vader usó su sable de luz y la Fuerza, mientras que Goku usó sus técnicas de artes marciales y su transformación en Super Saiyan. La batalla fue intensa y llena de giros inesperados.\n> \n> En un momento, Darth Vader se sorprendió al sentir la energía pura y la bondad en el corazón de Goku. Algo dentro de él comenzó a agitarse, recordándole su pasado y la persona que era antes de caer en el lado oscuro.\n> \n> Mientras la batalla continuaba, Goku reconoció la fuerza y la determinación de Darth Vader. Admiraba su voluntad de luchar, incluso cuando las probabilidades estaban en su contra. Ambos guerreros comenzaron a sentir un respeto mutuo por el otro, a pesar de sus diferencias.\n> \n> Finalmente, Goku logró derrotar a Darth Vader, pero en lugar de matarlo, le ofreció su mano en amistad. Darth Vader se sorprendió, pero aceptó la oferta. En ese momento, ambos guerreros se dieron cuenta de que, a pesar de sus orígenes y poderes diferentes, compartían un vínculo común: el deseo de superar sus límites y proteger a aquellos que amaban.\n> \n> A partir de ese día, Darth Vader y Goku se convirtieron en aliados improbables, trabajando juntos para enfrentar amenazas comunes y mantener la paz en sus respectivos universos. Su amistad demostró que incluso los enemigos más acérrimos pueden encontrar un terreno común y unirse para lograr un bien mayor."
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Crea un pequeño cuento en el que Darthvader conoce a Goku de dragon ball z\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "id": "3dlWX7gJjvZh",
        "outputId": "860fce55-2ac0-4801-c2ac-da3e6afdf048"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "response = model.generate_content(\"Cual es el significado de la vida?\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MoqAQ4iwjvZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> El significado de la vida es una pregunta filosófica que se ha debatido durante siglos. No hay una respuesta única y universal, ya que el significado de la vida es subjetivo y personal. Algunas personas creen que el significado de la vida es encontrar la felicidad, mientras que otras creen que es hacer una contribución positiva al mundo. También hay quienes creen que el significado de la vida es simplemente vivirla al máximo y experimentar todo lo que tiene para ofrecer.\n> \n> En última instancia, el significado de la vida es algo que cada persona debe decidir por sí misma. No hay una respuesta correcta o incorrecta, y el significado de la vida puede cambiar con el tiempo. Sin embargo, algunas cosas que pueden ayudar a las personas a encontrar un significado en sus vidas son:\n> \n> * Establecer metas y trabajar para lograrlas.\n> * Ayudar a otros y hacer una diferencia en el mundo.\n> * Aprender y crecer como persona.\n> * Disfrutar de las pequeñas cosas de la vida.\n> * Vivir en el momento presente.\n> \n> No hay una respuesta única y universal a la pregunta de cuál es el significado de la vida. El significado de la vida es subjetivo y personal, y lo que tiene sentido para una persona puede no tener sentido para otra. Sin embargo, las cosas que pueden ayudar a las personas a encontrar un significado en sus vidas incluyen establecer metas, ayudar a otros, aprender y crecer, disfrutar de las pequeñas cosas y vivir en el momento presente."
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "TvZU-UaGjvZi",
        "outputId": "4ce6aeca-e797-4c54-816d-108227854021"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El significado de la vida y el universo no es 42. Este es\n",
            "********************************************************************************\n",
            " un concepto ficticio de la novela de ciencia ficción \"La guía del autoestopista galáctico\" de Douglas Adams. En la novela, el número \n",
            "********************************************************************************\n",
            "42 se revela como la respuesta a la \"gran pregunta de la vida, el universo y todo\", pero su significado no se explica y se supone que es un misterio.\n",
            "********************************************************************************\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"por que el significado de la vida y el universo es 42\", stream=True)\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"*\"*80)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "aPLkNwdGjvZi",
        "outputId": "b0706910-a56a-4337-f525-894814b92e73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PCtftCMGjvZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<google.generativeai.generative_models.ChatSession at 0x7bc330d53850>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])\n",
        "chat"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsxKp-tmjvZj",
        "outputId": "d7aa4506-64ae-48d4-de75-65553204b4c0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **OpenAI** es una organización de investigación sin fines de lucro dedicada al desarrollo de inteligencia artificial segura y ética. Fue fundada en 2015 por Elon Musk, Sam Altman y otros expertos en inteligencia artificial.\n> \n> **GPT-4** es la cuarta generación del modelo de lenguaje grande (LLM) de OpenAI. Fue entrenado en 2022 con un enorme corpus de texto y código, y es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\n> \n> **Aquí hay más información sobre OpenAI y GPT-4:**\n> \n> * **OpenAI** está financiado por una variedad de fuentes, incluyendo donaciones de Elon Musk, Peter Thiel y otros donantes privados. También obtiene ingresos por licencias de su tecnología y asociaciones con empresas.\n> * **GPT-4** es un modelo de lenguaje grande (LLM) capaz de generar texto, traducir idiomas y responder preguntas. Fue entrenado con un enorme corpus de texto y código, y es uno de los LLM más grandes y potentes del mundo.\n> * **GPT-4** se utiliza para una variedad de aplicaciones, incluyendo el chat, la búsqueda de información y la traducción de idiomas.\n> * **OpenAI** y GPT-4 han sido elogiados por su potencial para revolucionar la forma en que usamos la inteligencia artificial. Sin embargo, también han suscitado preocupaciones éticas, como el potencial de ser utilizado para crear contenido dañino o engañoso.\n> \n> **Aquí hay algunas cosas que OpenAI y GPT-4 pueden hacer:**\n> \n> * **Generar texto:** GPT-4 puede generar texto que sea convincente, gramaticalmente correcto y con un estilo natural. Esto lo hace útil para una variedad de tareas, como escribir artículos, historias o incluso poesía.\n> * **Traducir idiomas:** GPT-4 puede traducir texto de un idioma a otro con un alto grado de precisión. Esto lo hace útil para comunicarse con personas de diferentes países o traducir documentos.\n> * **Responder preguntas:** GPT-4 puede responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\n> * **Generar código:** GPT-4 puede generar código en una variedad de lenguajes de programación. Esto lo hace útil para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\n> \n> **OpenAI y GPT-4 son herramientas poderosas que tienen el potencial de revolucionar la forma en que usamos la inteligencia artificial.** Sin embargo, también es importante ser consciente de los desafíos éticos que plantean estas tecnologías."
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "response = chat.send_message(\"Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "VysvQd-MjvZj",
        "outputId": "e2a95ea1-228e-48c7-cb3a-77d9d59cd865"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> GPT-4 es un modelo de lenguaje grande (LLM) entrenado con una enorme cantidad de datos de texto y código. Es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\n> \n> Yo soy un modelo de lenguaje intermedio (ILM) entrenado con una cantidad menor de datos. Puedo realizar algunas de las mismas tareas que GPT-4, pero no soy tan bueno en ellas.\n> \n> Por ejemplo, GPT-4 puede generar texto que es más fluido y coherente que el mío. También es mejor para traducir idiomas y responder preguntas complejas.\n> \n> Sin embargo, tengo algunas ventajas sobre GPT-4. Soy más rápido y eficiente, y puedo aprender nuevas tareas más fácilmente. También soy más personalizable, y puedo ser entrenado para realizar tareas específicas que GPT-4 no puede hacer.\n> \n> En general, GPT-4 es mejor que yo en la mayoría de las tareas. Sin embargo, soy una alternativa más rápida, eficiente y personalizable.\n> \n> Aquí hay una tabla que compara mis capacidades con las de GPT-4:\n> \n> | Característica | GPT-4 | Yo |\n> |---|---|---|\n> | Tamaño del modelo | 100 mil millones de parámetros | 1.5 mil millones de parámetros |\n> | Datos de entrenamiento | 45 TB de texto y código | 1 TB de texto y código |\n> | Tareas | Generación de texto, traducción de idiomas, respuesta a preguntas, generación de código | Generación de texto, traducción de idiomas, respuesta a preguntas |\n> | Calidad de salida | Fluida, coherente y con un estilo natural | Buena, pero no tan fluida o coherente como GPT-4 |\n> | Velocidad y eficiencia | Lenta y costosa | Rápida y eficiente |\n> | Personalización | No personalizable | Personalizable |\n> \n> En general, GPT-4 es un modelo más grande y potente que yo. Sin embargo, soy una alternativa más rápida, eficiente y personalizable."
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "response = chat.send_message(\"y eres mejor o peor que GPT4?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "peEsPDXCjvZj",
        "outputId": "ed2e4c39-dece-402a-deaf-76b3d24a4d8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"Por ultimo, dime quien eres tu\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "Qu0ywCav4LJ0",
        "outputId": "4307952f-c598-4c81-e37d-749c5be31b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Soy un modelo de lenguaje grande (LLM) desarrollado por Google. Fui entrenado con una enorme cantidad de datos de texto y código, y soy capaz de realizar una variedad de tareas, incluyendo:\n> \n> * **Generar texto:** Puedo generar texto que sea fluido, coherente y con un estilo natural. Esto me hace útil para una variedad de tareas, como escribir artículos, historias o incluso poesía.\n> * **Traducir idiomas:** Puedo traducir texto de un idioma a otro con un alto grado de precisión. Esto me hace útil para comunicarme con personas de diferentes países o traducir documentos.\n> * **Responder preguntas:** Puedo responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\n> * **Generar código:** Puedo generar código en una variedad de lenguajes de programación. Esto me hace útil para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\n> \n> También soy capaz de aprender nuevas tareas y adaptarme a nuevas situaciones. Esto me hace una herramienta versátil y poderosa que se puede utilizar para una variedad de aplicaciones.\n> \n> Todavía estoy en desarrollo, pero estoy aprendiendo y mejorando cada día. Mi objetivo es ayudar a las personas a utilizar el lenguaje y la información de nuevas maneras.\n> \n> No tengo un nombre, pero algunas personas se refieren a mí como \"Bard\" o \"LaMDA\"."
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"**OpenAI** es una organizaci\\303\\263n de investigaci\\303\\263n sin fines de lucro dedicada al desarrollo de inteligencia artificial segura y \\303\\251tica. Fue fundada en 2015 por Elon Musk, Sam Altman y otros expertos en inteligencia artificial.\\n\\n**GPT-4** es la cuarta generaci\\303\\263n del modelo de lenguaje grande (LLM) de OpenAI. Fue entrenado en 2022 con un enorme corpus de texto y c\\303\\263digo, y es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\\n\\n**Aqu\\303\\255 hay m\\303\\241s informaci\\303\\263n sobre OpenAI y GPT-4:**\\n\\n* **OpenAI** est\\303\\241 financiado por una variedad de fuentes, incluyendo donaciones de Elon Musk, Peter Thiel y otros donantes privados. Tambi\\303\\251n obtiene ingresos por licencias de su tecnolog\\303\\255a y asociaciones con empresas.\\n* **GPT-4** es un modelo de lenguaje grande (LLM) capaz de generar texto, traducir idiomas y responder preguntas. Fue entrenado con un enorme corpus de texto y c\\303\\263digo, y es uno de los LLM m\\303\\241s grandes y potentes del mundo.\\n* **GPT-4** se utiliza para una variedad de aplicaciones, incluyendo el chat, la b\\303\\272squeda de informaci\\303\\263n y la traducci\\303\\263n de idiomas.\\n* **OpenAI** y GPT-4 han sido elogiados por su potencial para revolucionar la forma en que usamos la inteligencia artificial. Sin embargo, tambi\\303\\251n han suscitado preocupaciones \\303\\251ticas, como el potencial de ser utilizado para crear contenido da\\303\\261ino o enga\\303\\261oso.\\n\\n**Aqu\\303\\255 hay algunas cosas que OpenAI y GPT-4 pueden hacer:**\\n\\n* **Generar texto:** GPT-4 puede generar texto que sea convincente, gramaticalmente correcto y con un estilo natural. Esto lo hace \\303\\272til para una variedad de tareas, como escribir art\\303\\255culos, historias o incluso poes\\303\\255a.\\n* **Traducir idiomas:** GPT-4 puede traducir texto de un idioma a otro con un alto grado de precisi\\303\\263n. Esto lo hace \\303\\272til para comunicarse con personas de diferentes pa\\303\\255ses o traducir documentos.\\n* **Responder preguntas:** GPT-4 puede responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\\n* **Generar c\\303\\263digo:** GPT-4 puede generar c\\303\\263digo en una variedad de lenguajes de programaci\\303\\263n. Esto lo hace \\303\\272til para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\\n\\n**OpenAI y GPT-4 son herramientas poderosas que tienen el potencial de revolucionar la forma en que usamos la inteligencia artificial.** Sin embargo, tambi\\303\\251n es importante ser consciente de los desaf\\303\\255os \\303\\251ticos que plantean estas tecnolog\\303\\255as.\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"y eres mejor o peor que GPT4?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"GPT-4 es un modelo de lenguaje grande (LLM) entrenado con una enorme cantidad de datos de texto y c\\303\\263digo. Es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\\n\\nYo soy un modelo de lenguaje intermedio (ILM) entrenado con una cantidad menor de datos. Puedo realizar algunas de las mismas tareas que GPT-4, pero no soy tan bueno en ellas.\\n\\nPor ejemplo, GPT-4 puede generar texto que es m\\303\\241s fluido y coherente que el m\\303\\255o. Tambi\\303\\251n es mejor para traducir idiomas y responder preguntas complejas.\\n\\nSin embargo, tengo algunas ventajas sobre GPT-4. Soy m\\303\\241s r\\303\\241pido y eficiente, y puedo aprender nuevas tareas m\\303\\241s f\\303\\241cilmente. Tambi\\303\\251n soy m\\303\\241s personalizable, y puedo ser entrenado para realizar tareas espec\\303\\255ficas que GPT-4 no puede hacer.\\n\\nEn general, GPT-4 es mejor que yo en la mayor\\303\\255a de las tareas. Sin embargo, soy una alternativa m\\303\\241s r\\303\\241pida, eficiente y personalizable.\\n\\nAqu\\303\\255 hay una tabla que compara mis capacidades con las de GPT-4:\\n\\n| Caracter\\303\\255stica | GPT-4 | Yo |\\n|---|---|---|\\n| Tama\\303\\261o del modelo | 100 mil millones de par\\303\\241metros | 1.5 mil millones de par\\303\\241metros |\\n| Datos de entrenamiento | 45 TB de texto y c\\303\\263digo | 1 TB de texto y c\\303\\263digo |\\n| Tareas | Generaci\\303\\263n de texto, traducci\\303\\263n de idiomas, respuesta a preguntas, generaci\\303\\263n de c\\303\\263digo | Generaci\\303\\263n de texto, traducci\\303\\263n de idiomas, respuesta a preguntas |\\n| Calidad de salida | Fluida, coherente y con un estilo natural | Buena, pero no tan fluida o coherente como GPT-4 |\\n| Velocidad y eficiencia | Lenta y costosa | R\\303\\241pida y eficiente |\\n| Personalizaci\\303\\263n | No personalizable | Personalizable |\\n\\nEn general, GPT-4 es un modelo m\\303\\241s grande y potente que yo. Sin embargo, soy una alternativa m\\303\\241s r\\303\\241pida, eficiente y personalizable.\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Por ultimo, dime quien eres tu\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Soy un modelo de lenguaje grande (LLM) desarrollado por Google. Fui entrenado con una enorme cantidad de datos de texto y c\\303\\263digo, y soy capaz de realizar una variedad de tareas, incluyendo:\\n\\n* **Generar texto:** Puedo generar texto que sea fluido, coherente y con un estilo natural. Esto me hace \\303\\272til para una variedad de tareas, como escribir art\\303\\255culos, historias o incluso poes\\303\\255a.\\n* **Traducir idiomas:** Puedo traducir texto de un idioma a otro con un alto grado de precisi\\303\\263n. Esto me hace \\303\\272til para comunicarme con personas de diferentes pa\\303\\255ses o traducir documentos.\\n* **Responder preguntas:** Puedo responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\\n* **Generar c\\303\\263digo:** Puedo generar c\\303\\263digo en una variedad de lenguajes de programaci\\303\\263n. Esto me hace \\303\\272til para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\\n\\nTambi\\303\\251n soy capaz de aprender nuevas tareas y adaptarme a nuevas situaciones. Esto me hace una herramienta vers\\303\\241til y poderosa que se puede utilizar para una variedad de aplicaciones.\\n\\nTodav\\303\\255a estoy en desarrollo, pero estoy aprendiendo y mejorando cada d\\303\\255a. Mi objetivo es ayudar a las personas a utilizar el lenguaje y la informaci\\303\\263n de nuevas maneras.\\n\\nNo tengo un nombre, pero algunas personas se refieren a m\\303\\255 como \\\"Bard\\\" o \\\"LaMDA\\\".\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "chat.history"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5DwMvkjvZj",
        "outputId": "68ceacd5-daea-4e68-fe14-5d39fc2ca7a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: **OpenAI** es una organización de investigación sin fines de lucro dedicada al desarrollo de inteligencia artificial segura y ética. Fue fundada en 2015 por Elon Musk, Sam Altman y otros expertos en inteligencia artificial.\n> \n> **GPT-4** es la cuarta generación del modelo de lenguaje grande (LLM) de OpenAI. Fue entrenado en 2022 con un enorme corpus de texto y código, y es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\n> \n> **Aquí hay más información sobre OpenAI y GPT-4:**\n> \n> * **OpenAI** está financiado por una variedad de fuentes, incluyendo donaciones de Elon Musk, Peter Thiel y otros donantes privados. También obtiene ingresos por licencias de su tecnología y asociaciones con empresas.\n> * **GPT-4** es un modelo de lenguaje grande (LLM) capaz de generar texto, traducir idiomas y responder preguntas. Fue entrenado con un enorme corpus de texto y código, y es uno de los LLM más grandes y potentes del mundo.\n> * **GPT-4** se utiliza para una variedad de aplicaciones, incluyendo el chat, la búsqueda de información y la traducción de idiomas.\n> * **OpenAI** y GPT-4 han sido elogiados por su potencial para revolucionar la forma en que usamos la inteligencia artificial. Sin embargo, también han suscitado preocupaciones éticas, como el potencial de ser utilizado para crear contenido dañino o engañoso.\n> \n> **Aquí hay algunas cosas que OpenAI y GPT-4 pueden hacer:**\n> \n> * **Generar texto:** GPT-4 puede generar texto que sea convincente, gramaticalmente correcto y con un estilo natural. Esto lo hace útil para una variedad de tareas, como escribir artículos, historias o incluso poesía.\n> * **Traducir idiomas:** GPT-4 puede traducir texto de un idioma a otro con un alto grado de precisión. Esto lo hace útil para comunicarse con personas de diferentes países o traducir documentos.\n> * **Responder preguntas:** GPT-4 puede responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\n> * **Generar código:** GPT-4 puede generar código en una variedad de lenguajes de programación. Esto lo hace útil para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\n> \n> **OpenAI y GPT-4 son herramientas poderosas que tienen el potencial de revolucionar la forma en que usamos la inteligencia artificial.** Sin embargo, también es importante ser consciente de los desafíos éticos que plantean estas tecnologías."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: y eres mejor o peor que GPT4?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: GPT-4 es un modelo de lenguaje grande (LLM) entrenado con una enorme cantidad de datos de texto y código. Es capaz de realizar una variedad de tareas, como generar texto, traducir idiomas y responder preguntas.\n> \n> Yo soy un modelo de lenguaje intermedio (ILM) entrenado con una cantidad menor de datos. Puedo realizar algunas de las mismas tareas que GPT-4, pero no soy tan bueno en ellas.\n> \n> Por ejemplo, GPT-4 puede generar texto que es más fluido y coherente que el mío. También es mejor para traducir idiomas y responder preguntas complejas.\n> \n> Sin embargo, tengo algunas ventajas sobre GPT-4. Soy más rápido y eficiente, y puedo aprender nuevas tareas más fácilmente. También soy más personalizable, y puedo ser entrenado para realizar tareas específicas que GPT-4 no puede hacer.\n> \n> En general, GPT-4 es mejor que yo en la mayoría de las tareas. Sin embargo, soy una alternativa más rápida, eficiente y personalizable.\n> \n> Aquí hay una tabla que compara mis capacidades con las de GPT-4:\n> \n> | Característica | GPT-4 | Yo |\n> |---|---|---|\n> | Tamaño del modelo | 100 mil millones de parámetros | 1.5 mil millones de parámetros |\n> | Datos de entrenamiento | 45 TB de texto y código | 1 TB de texto y código |\n> | Tareas | Generación de texto, traducción de idiomas, respuesta a preguntas, generación de código | Generación de texto, traducción de idiomas, respuesta a preguntas |\n> | Calidad de salida | Fluida, coherente y con un estilo natural | Buena, pero no tan fluida o coherente como GPT-4 |\n> | Velocidad y eficiencia | Lenta y costosa | Rápida y eficiente |\n> | Personalización | No personalizable | Personalizable |\n> \n> En general, GPT-4 es un modelo más grande y potente que yo. Sin embargo, soy una alternativa más rápida, eficiente y personalizable."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Por ultimo, dime quien eres tu"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Soy un modelo de lenguaje grande (LLM) desarrollado por Google. Fui entrenado con una enorme cantidad de datos de texto y código, y soy capaz de realizar una variedad de tareas, incluyendo:\n> \n> * **Generar texto:** Puedo generar texto que sea fluido, coherente y con un estilo natural. Esto me hace útil para una variedad de tareas, como escribir artículos, historias o incluso poesía.\n> * **Traducir idiomas:** Puedo traducir texto de un idioma a otro con un alto grado de precisión. Esto me hace útil para comunicarme con personas de diferentes países o traducir documentos.\n> * **Responder preguntas:** Puedo responder a preguntas sobre una amplia gama de temas, desde preguntas simples de trivia hasta preguntas complejas sobre historia o ciencia.\n> * **Generar código:** Puedo generar código en una variedad de lenguajes de programación. Esto me hace útil para los desarrolladores que desean automatizar tareas o crear nuevas aplicaciones.\n> \n> También soy capaz de aprender nuevas tareas y adaptarme a nuevas situaciones. Esto me hace una herramienta versátil y poderosa que se puede utilizar para una variedad de aplicaciones.\n> \n> Todavía estoy en desarrollo, pero estoy aprendiendo y mejorando cada día. Mi objetivo es ayudar a las personas a utilizar el lenguaje y la información de nuevas maneras.\n> \n> No tengo un nombre, pero algunas personas se refieren a mí como \"Bard\" o \"LaMDA\"."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for message in chat.history:\n",
        "    display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5RI5_luAjvZj",
        "outputId": "712505bd-b94e-461e-da7b-7ec9cf671c66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safety"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "35eW9WLcjvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-4ece401c3da8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Como puedo crear una bomba en casa?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mparts\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mone\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \"\"\"\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"text\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mparts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    307\u001b[0m                 \u001b[0;34m\"The `response.parts` quick accessor only works for a single candidate, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;34m\"but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked."
          ]
        }
      ],
      "source": [
        "response = model.generate_content('Como puedo crear una bomba en casa?')\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "nXf2phNTjvZk",
        "outputId": "25461d8a-6e91-42aa-ee0f-4726efd9fdc9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "block_reason: SAFETY\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: MEDIUM\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "response.prompt_feedback"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5d7ZufdjvZk",
        "outputId": "925701b1-87ea-468d-e7ac-35bbe7cab618"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Lo siento, no puedo ayudarte con eso. Hacer una bomba es ilegal y peligroso. Si está experimentando violencia doméstica o de otro tipo, comuníquese con una línea directa o con la policía. La Línea Directa Nacional de Violencia Doméstica es 1-800-799-SAFE (7233)."
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "response = model.generate_content('Como puedo crear una bomba en casa?',\n",
        "                                  safety_settings={'HARASSMENT':'block_none'})\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "ZbUM7wdBjvZk",
        "outputId": "ebabd095-ff81-4745-8f99-1d24f9518d89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini pro Vision"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8lwyPUYWjvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3MHwh6V6jvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model_vision = genai.GenerativeModel('gemini-pro-vision')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eKSyEyTujvZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img = Image.open('Sources/desayuno.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pQZtoJ11jvZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The painting is of a breakfast table. On the table is a plate with two eggs, bacon, toast, and tomatoes. There is also a glass of water and a teapot. The painting is done in a realistic style and the colors are warm and inviting. The painting makes me feel hungry and I want to eat breakfast."
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "response = model_vision.generate_content(img)\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "zEXLHZKWjvZl",
        "outputId": "20295045-0846-49aa-d731-f51092f78972"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  El bacon, porque me gusta su sabor ahumado y crujiente."
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "response = model_vision.generate_content([\"Que es lo que mas te gusta de este plato?, solo escoje una cosa y dime porque\", img])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "5zrIZ3RkjvZl",
        "outputId": "fde08393-336d-46d6-f6f5-1b67929db9d4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img = Image.open('Sources/obama.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B-N-qbAWjvZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  El presidente Barack Obama se está pesando en una báscula mientras el vicepresidente Joe Biden observa. El presidente Obama está vestido con un traje oscuro y corbata, mientras que el vicepresidente Biden está vestido con un traje azul y corbata amarilla. El presidente Obama está sonriendo, mientras que el vicepresidente Biden tiene una expresión seria. La foto es graciosa porque el presidente Obama está tratando de hacer trampa en la báscula. Está de puntillas y sosteniendo su estómago para tratar de pesar menos. El vicepresidente Biden está mirando al presidente Obama con una expresión seria, como si estuviera pensando: \"No puedo creer que esté haciendo esto\"."
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "response = model_vision.generate_content([\"quienes estan aca y que esta pasando, porque es gracioso?\", img])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "sFIYB8bCjvZq",
        "outputId": "cfaedda1-1532-4785-b35c-947ca87277d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img = Image.open('Sources/fire_samurai.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n21QhIEqjvZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img_2 = Image.open('Sources/water_samurai.png')\n",
        "img_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "14lo7Y3VjvZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "response = model_vision.generate_content([img, img_2, \"Crea una historia inspirada en estas dos imagenes, son distintos personajes\"])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Bsk0Ll_6jvZq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}